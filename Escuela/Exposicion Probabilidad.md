DistribuciÃ³n a priori: Representa lo que creemos sobre un parÃ¡metro antes de ver los datos.
	Ejemplo: No sabemos si una moneda estÃ¡ cargada (no sea 50-50) pero cÃ³mo no la hemos lanzado aÃºn entonces asumimos que es justa
DistribuciÃ³n a Posteriori: Es nuestra nueva creencia actualizada despuÃ©s de ver los datos o realizar un experimento.
	Ejemplo: Lanzamos la moneda 5 veces y vemos que cayÃ³ 4 veces cara y 1 vez cruz, por lo que nuestra creencia actualizada es que la moneda 	probablemente estÃ¡ cargada
Verosimilitud: La verosimilitud es una forma de medir quÃ© tan compatibles son los datos que observaste con una hipÃ³tesis concreta.
	Imagina que ocurriÃ³ un crimen y tienes 3 sospechosos:
    Sospechoso A: Estaba en la escena y tiene un motivo.
    Sospechoso B: Vive en otro paÃ­s.
    Sospechoso C: No tiene coartada.
ğŸ” Luego encuentras una huella digital.
Preguntas: â€œSi el sospechoso A fuera el culpable, Â¿quÃ© tan probable es esta huella?â€ â†’ alta verosimilitud
Ahora con el sospechoso B (que vive lejos), dices: â€œSi Ã©l fuera el culpable, Â¿es probable que deje esta huella aquÃ­?â€ â†’ baja verosimilitud
Inferencia Bayeisiana: ![[Pasted image 20250622180103.png]]![[Pasted image 20250622180134.png]]


SupÃ³n esto:

- Sabes que en una fiesta hay **10 pasteles**.
    
- Uno de ellos **podrÃ­a estar envenenado**.
    
- Antes de ver nada, piensas que **todos tienen la misma probabilidad** de estar envenenado: eso es tu **prior** (creencia previa).
MÃ©todo Monte Carlo: La simulaciÃ³n de Monte Carlo es un tipo de algoritmo computacional que utiliza muestreo aleatorio repetido para obtener la probabilidad de que se produzca un rango de resultados.
	Ejemplo: No sabemos el valor de pi y queremos aproximarlo
	Creamos la siguiente figura
	![[Pasted image 20250621203249.png]]
	Sabemos que el area del circulo es piR^2
	El area del cuadrado es 4R^2
	Por lo tanto tenemos que circulo/cuadrado  (proporcion)= pi/4
	Con un generador de numeros aleatorios generamos coordenadas dentro del espacio y llevamos cuenta de cuÃ¡ntos puntos quedan dentro y fuera del cÃ­rculo
	Si generamos 100 puntos y tenemos que 81 cayeron dentro del circulo y 19 no
	Por lo tanto 81/100 = pi / 4;  pi = (81x4)/100 = 3.24
	El error de este metodo es Raiz de n donde n es el numero de veces que hacemos el experimento
![[Pasted image 20250622152918.png]]
Muestreo por rechazo (aceptacion-rechazo)
	tÃ©cnica utilizada para generar muestras aleatorias de una distribuciÃ³n objetivo, especialmente cuando es difÃ­cil o imposible muestrear directamente de ella
	Proponemos g(s) que es una distribucion mucho mas sencilla que f(s) y que ademas se acerca a esta ultima
	![[Pasted image 20250621213543.png]]
	Escalamos g(s) por M para que este por encima de f(s) (asi tambien aseguramos que el resultado siempre va a estar en rango 0 a 1)
	![[Pasted image 20250621213734.png]]
	Para saber si aceptamos o no una muestra seguimos lo siguiente que nos va a dar una probabilidad 0-100%, nosotros decidimos el umbral
	![[Pasted image 20250621214602.png]]
	aclaraciones: Conocer una funciÃ³n de distribuciÃ³n solo te permite calcular la probabilidad de una muestra. Generar muestras a partir de esa funciÃ³n es una tarea diferente.
	Ejemplo: Sabes que una variable sigue una **distribuciÃ³n normal**:
	![[Pasted image 20250621214715.png]]
	Eso significa que **puedes calcular** cosas como:
- Â¿CuÃ¡l es la probabilidad de que xxx estÃ© entre -1 y 1?
- Â¿CuÃ¡l es la densidad en x=0.5x = 0.5x=0.5? (Es decir, f(0.5)f(0.5)f(0.5))
- Ahora imagina que quieres hacer una simulaciÃ³n y necesitas **nÃºmeros aleatorios que se comporten como si vinieran de esa distribuciÃ³n normal**.
ğŸ” AquÃ­ no basta con conocer la fÃ³rmula. Necesitas **un proceso (algoritmo)** que genere esos valores.
ğŸ² Por ejemplo:
- Un generador que te dÃ© nÃºmeros como: -0.8, 0.3, 1.2, -1.4, etc., **siguiendo la forma de la curva normal**.
- Esos nÃºmeros deben salir con mÃ¡s frecuencia donde la curva es mÃ¡s alta, y menos donde es baja.
	Desventajas del muestreo por rechazo: es dificil encontrar un g(s) que sea simple y que a la vez se parezca a la funcion
	![[Pasted image 20250621214921.png]]
	Este metodo no tiene memoria, por lo que si encontramos un valor que es muy probable en f(x) deberiamos de generar mas numeros por ese rango, sin embargo el metodo sigue generando numeros aleatorios sin ningun bias, aqui es donde el metodo MCMC entra

Muestreo Monte Carlo por cadenas de Markov (MCMC - Metropolis Hastings):
	Cadenas de MÃ¡rkov: modelo matemÃ¡tico que describe una secuencia de eventos donde la probabilidad de que ocurra un evento depende Ãºnicamente del estado inmediatamente anterior
		Ejemplo: En un restaurante te dan la carta y puedes elegir entre carne, cerdo o pescado	
		despuÃ©s de elegir, te dan a elegir entre 3 bebidas, vino tino, cerveza, refresco
		La selecciÃ³n de la bebida depende de que elegiste para comer
		
	El metodo: el siguiente muestreo depende del ultimo
	Distribucion estacionaria: propiedad de las cadenas de Markov, dice que si la cadena llega a esta distribucion entonces se va a quedar en esa distribucion por el resto de las muestras "a probability distribution that remains unchanged over time as the chain evolves"
	Entonces, lo que queremos es diseÃ±ar una cadena de markov cuya distribuciÃ³n estacionaria sea nuestra f(x) )(nuestra distribuciÃ³n target de la que queremos sacar muestras)
	Comenzamos en un punto "a" al azar y proponemos el punto "b", si f(b) > f(a) entonces T(a->b) = 1 (100%)
	en caso contrario, la prob de aceptar esa propuesta de punto "b" es f(b) / f(b) esto porque queremos aun asi sacar muestras de la cola de la distribucion, si no hacemos esto, nos quedariamos atrapados en un solo punto

### Usos en simulaciones

## 1. ğŸŸ¢ **Monte Carlo directo**

### ğŸ² Simular la probabilidad de que al menos dos personas compartan cumpleaÃ±os en un grupo (el famoso "problema del cumpleaÃ±os")

---

### ğŸ§  Â¿QuÃ© queremos hacer?

Queremos saber:

> â€œÂ¿CuÃ¡l es la probabilidad de que en un grupo de 23 personas, al menos dos cumplan aÃ±os el mismo dÃ­a?â€

Este cÃ¡lculo exacto es difÃ­cil manualmente, pero se puede hacer fÃ¡cilmente por simulaciÃ³n.

---

### ğŸ‘Ÿ CÃ³mo lo hacemos (Monte Carlo):

1. Simulamos 10,000 grupos de 23 personas.
    
2. Para cada grupo, generamos un cumpleaÃ±os aleatorio (1â€“365) para cada persona.
    
3. Contamos cuÃ¡ntos grupos tienen **al menos una coincidencia**.
    

---

### ğŸ¤¯ Â¿Por quÃ© es Monte Carlo?

Porque **podemos generar muestras directamente** de la distribuciÃ³n (cumpleaÃ±os al azar), sin necesidad de fÃ³rmulas complicadas.

---

### ğŸ§ AplicaciÃ³n real:

Simular la probabilidad de colisiones en IDs generadas aleatoriamente (por ejemplo, en bases de datos, cÃ³digos QR, claves Ãºnicas).

---

## 2. ğŸ”´ **Rechazo**

### ğŸš¦ Control de calidad: detectar si una pieza es aceptable segÃºn su medida

---

### ğŸ§  Â¿QuÃ© queremos hacer?

SupÃ³n que fabricas tornillos, y **solo aceptas los que miden entre 19.8 mm y 20.2 mm**. La mÃ¡quina produce tornillos con un tamaÃ±o entre 18 mm y 22 mm, distribuidos de forma desconocida.

No puedes generar tornillos **directamente dentro del rango aceptable**, pero puedes:

---

### ğŸ‘Ÿ CÃ³mo lo haces (Rechazo):

1. Generas tornillos al azar entre 18 y 22 mm.
    
2. Si el tornillo estÃ¡ entre 19.8 y 20.2 mm â†’ lo **aceptas**.
    
3. Si no, lo rechazas.
    

---

### ğŸ¤¯ Â¿Por quÃ© es rechazo?

Porque estÃ¡s **proponiendo valores de una distribuciÃ³n mÃ¡s amplia**, y **filtrando los que te interesan**.

---

### ğŸ§ AplicaciÃ³n real:

SimulaciÃ³n de producciÃ³n para saber **cuÃ¡ntas piezas necesitarÃ¡s producir para tener suficientes dentro de especificaciones**, o estimar la tasa de desperdicio.

---

## 3. ğŸ” **MCMC (Metropolis-Hastings)**

### ğŸ¥ Estimar la prevalencia real de una enfermedad en una poblaciÃ³n

---

### ğŸ§  Â¿QuÃ© queremos hacer?

Tienes datos de pruebas mÃ©dicas:

- La prueba tiene un **5% de falsos positivos** y un **2% de falsos negativos**.
    
- De 1,000 personas, 100 dieron positivo.
    

Quieres estimar:

> â€œÂ¿CuÃ¡l es la proporciÃ³n real de personas enfermas en la poblaciÃ³n?â€

Este problema **tiene muchas fuentes de incertidumbre**, y es difÃ­cil calcular una distribuciÃ³n exacta.

---

### ğŸ‘Ÿ CÃ³mo lo haces (MCMC):

1. Empiezas con una suposiciÃ³n: por ejemplo, 10% de personas enfermas.
    
2. Propones cambiarla un poco (por ejemplo, subir a 12%).
    
3. EvalÃºas si **con ese nuevo valor** los datos observados (100 positivos) serÃ­an mÃ¡s o menos probables.
    
4. Si el nuevo valor explica mejor los datos, lo aceptas.
    
5. Repites muchas veces y ves cÃ³mo se distribuyen tus hipÃ³tesis.
    

---

### ğŸ¤¯ Â¿Por quÃ© es MCMC?

Porque **no puedes generar muestras directas**, ni aplicar rechazo eficientemente.  
Te mueves **paso a paso por el espacio de hipÃ³tesis**, generando una distribuciÃ³n realista de posibilidades.

---

### ğŸ§ AplicaciÃ³n real:

Estimar tasas de enfermedades, fallos en sistemas de seguridad, proporciÃ³n de votos ocultos, etc., **cuando los datos son ruidosos o indirectos**.

---

## ğŸ—‚ï¸ RESUMEN DE LOS EJEMPLOS

|MÃ©todo|Ejemplo real|QuÃ© simula|Tipo de tarea|
|---|---|---|---|
|Monte Carlo|Probabilidad de compartir cumpleaÃ±os|Generar muestras directas para estimar una probabilidad|SimulaciÃ³n sencilla y directa|
|Rechazo|Control de calidad de tornillos|Filtrar valores buenos desde una distribuciÃ³n amplia|Cuando tienes una condiciÃ³n de corte|
|MCMC|Estimar proporciÃ³n real de enfermos|Explorar hipÃ³tesis paso a paso segÃºn quÃ© tan bien explican los datos|Para problemas con incertidumbre compleja|
