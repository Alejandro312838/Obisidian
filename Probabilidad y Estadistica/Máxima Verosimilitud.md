La m√°xima verosimilitud (Maximum Likelihood) es un ==m√©todo estad√≠stico utilizado para estimar los par√°metros de un modelo==. En esencia, busca los valores de los par√°metros que hacen que los datos observados sean lo m√°s probables posible. Se utiliza en una variedad de campos, incluyendo la estad√≠stica, el aprendizaje autom√°tico y la bioinform√°tica.¬†

##### **siempre parte del supuesto de que los datos provienen de una distribuci√≥n definida**.

En t√©rminos m√°s simples:
1. **1.** **Funci√≥n de Verosimilitud:**
    Se define una funci√≥n que describe la probabilidad de observar los datos que tenemos, dado un conjunto espec√≠fico de valores para los par√°metros del modelo.¬†
    
- **2.** **Maximizaci√≥n:**
    El objetivo es encontrar los valores de los par√°metros que maximizan esta funci√≥n de verosimilitud. Estos valores son considerados la estimaci√≥n de m√°xima verosimilitud.¬†
    
- **3.** **Interpretaci√≥n:**
    
    La estimaci√≥n de m√°xima verosimilitud nos da los valores de los par√°metros que mejor explican los datos observados, seg√∫n el modelo elegido

![[Pasted image 20250717164731.png]]
Debemos encontrar la funcion de prob azul (pues es donde los valores son mas probables) o bien, debemos de estimar los parametros de la muestra morada (como este caso es una distribucion normal entonces debemos de encontrar su media y su desviacion estandar)

The true distribution from which the data were generated was f1 ~ N(10, 2.25), which is the blue curve in the figure above.

# üìä M√°xima Verosimilitud (MLE)

## üß© ¬øQu√© es la MLE?
La **M√°xima Verosimilitud (MLE)** es un m√©todo para estimar par√°metros desconocidos de una poblaci√≥n. Busca los valores de los par√°metros que **hacen m√°s probable haber observado la muestra que tenemos**.

---

## üßÆ Pasos para encontrar la funci√≥n de verosimilitud

1. **Identificar la distribuci√≥n de la muestra**  
   Asume que los datos provienen de una distribuci√≥n conocida (ej. normal, exponencial, binomial, etc.).

2. **Escribir la funci√≥n de densidad o probabilidad**  
   Escribe \( f(x_i; \theta) \), la funci√≥n de probabilidad o densidad para una sola observaci√≥n, en funci√≥n del par√°metro desconocido \( \theta \).

3. **Construir la funci√≥n de verosimilitud**  
   Si la muestra es \( x_1, x_2, ..., x_n \), entonces:
$$
   L(\theta) = \prod_{i=1}^{n} f(x_i; \theta)
   $$
   

5. **Tomar logaritmo (opcional pero recomendado)**  
   Para simplificar, se suele usar la log-verosimilitud:

   \[$$
   \log L(\theta) = \sum_{i=1}^{n} \log f(x_i; \theta)
   $$

6. **Derivar e igualar a cero**  
   Deriva respecto al par√°metro \( \theta \), y resuelve \( \frac{d}{d\theta} \log L(\theta) = 0 \).

7. **Verificar que es un m√°ximo**  
   Usa la segunda derivada o analiza el comportamiento de la funci√≥n para confirmar que encontraste un m√°ximo.

---

## üìå Notas importantes

### ‚úÖ La MLE tiene **una forma fija para cada distribuci√≥n**

- Por ejemplo, si los datos vienen de una **normal con varianza conocida**, la MLE de la media \( \mu \) **siempre ser√°** el promedio muestral:
  
  \[$$
  \hat{\mu} = \frac{1}{n} \sum x_i
  $$

- Si los datos vienen de una **exponencial**, la MLE del par√°metro \( \lambda \) ser√°:

  $$
  \hat{\lambda} = \frac{n}{\sum x_i} = \frac{1}{\bar{x}}
  $$

> ‚ú® *Es decir, la f√≥rmula del estimador es fija para cada tipo de distribuci√≥n. Lo que cambia con la muestra es el valor num√©rico del estimador, no la forma general.*

---

### ‚ùì ¬øQu√© pasa si **no se conoce la distribuci√≥n**?

Si la distribuci√≥n de la poblaci√≥n **no est√° bien definida** o **no quieres asumir una forma espec√≠fica**, **no puedes usar MLE tradicional**. En ese caso puedes:

- Usar una **distribuci√≥n aproximada** si tiene sentido (modelo param√©trico).
- Usar **m√©todos no param√©tricos** (como histogramas, estimadores kernel, bootstrap).
- Usar modelos **semi-param√©tricos**, donde partes del modelo son conocidos y otras no.

> ‚ö†Ô∏è *La MLE requiere una funci√≥n de densidad conocida. Si no puedes definirla, necesitas t√©cnicas alternativas.*

---

## üß† Resumen

- La MLE busca el par√°metro que maximiza la probabilidad de observar la muestra.
- Cada distribuci√≥n tiene una **f√≥rmula MLE fija**.
- Si no conoces la distribuci√≥n, debes usar m√©todos **no param√©tricos o semi-param√©tricos**.


